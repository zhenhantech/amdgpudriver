# Test 5: çœŸå®AIæ¨¡å‹æµ‹è¯•ç»“æœ

**æ—¥æœŸ**: 2026-01-29  
**çŠ¶æ€**: ğŸ”„ **éƒ¨åˆ†å®Œæˆï¼ˆBaselineæˆåŠŸï¼ŒXSchedé‡åˆ°HIP contexté—®é¢˜ï¼‰**

---

## âœ… å·²å®Œæˆï¼šBaselineæµ‹è¯•

### æµ‹è¯•é…ç½®

**Workload**:
- **High Priority**: ResNet-18, batch=1, ç›®æ ‡20 req/s
- **Low Priority**: ResNet-50, batch=256, è¿ç»­è¿è¡Œ
- **Duration**: 60ç§’
- **å®ç°**: Python + PyTorch + threading
- **XSched**: DISABLED (baseline)

### Baselineç»“æœ (æ— XSched)

```
High Priority (ResNet-18):
  Samples: 699 requests
  Throughput: 11.64 req/s (ç›®æ ‡20)
  
  å»¶è¿Ÿ:
    Avg:  81.18 ms
    P50:  92.49 ms
    P95: 115.54 ms
    P99: 117.09 ms
    Max: 600.74 ms

Low Priority (ResNet-50, batch=256):
  Iterations: 466
  Throughput: 7.76 iter/s
  Images/sec: 1985.6
```

### å…³é”®å‘ç° ğŸ“Š

#### 1. çœŸå®æ¨¡å‹ vs çŸ©é˜µä¹˜æ³•å¯¹æ¯”

| æŒ‡æ ‡ | Test 4 (çŸ©é˜µä¹˜æ³•) | Test 5 (çœŸå®ResNet) | å·®å¼‚ |
|------|------------------|-------------------|------|
| **Workload** | 1024Ã—1024Ã—4 + 2048Ã—2048Ã—16 | ResNet-18Ã—1 + ResNet-50Ã—256 | - |
| **High P50** | 24.82 ms | **92.49 ms** | **+273%** âš ï¸âš ï¸âš ï¸ |
| **High P99** | 29.63 ms | **117.09 ms** | **+295%** âš ï¸âš ï¸âš ï¸ |
| **Highåå** | 19.99 req/s | **11.64 req/s** | **-42%** âš ï¸âš ï¸ |
| **Lowåå** | 3.16 iter/s | **7.76 iter/s** | +145% â­ |

**åˆ†æ**:
1. âš ï¸ **çœŸå®ResNet-18å»¶è¿Ÿè¿œé«˜äºçŸ©é˜µä¹˜æ³•** (92 vs 25ms, +273%)
   - åŸå› ï¼šå·ç§¯ã€BNã€æ¿€æ´»ç­‰æ“ä½œæ¯”å•çº¯çŸ©é˜µä¹˜æ³•å¤æ‚
   - å†…å­˜è®¿é—®æ¨¡å¼æ›´å¤æ‚
   - Kernel launchå¼€é”€æ›´å¤§

2. âš ï¸ **é«˜ä¼˜å…ˆçº§ååæœªè¾¾æ ‡** (11.64 vs 20 req/s)
   - GPUèµ„æºç«äº‰éå¸¸æ¿€çƒˆ
   - ResNet-50 batch=256å ç”¨å¤§é‡èµ„æº

3. â­ **ä½ä¼˜å…ˆçº§ResNet-50ååæ›´é«˜** (7.76 vs 3.16 iter/s)
   - ä½†batch sizeä¸åŒ (256 vs 16)
   - å½’ä¸€åŒ–æ¯”è¾ƒï¼šimages/s = 1985 vs 50 (Test 4)
   - å®é™…workloadæ›´åˆç†

#### 2. GPUèµ„æºç«äº‰éªŒè¯

**è¯æ®**:
- ç›®æ ‡ååï¼š20 req/s â†’ å®é™…ï¼š11.64 req/s (-42%)
- è¯´æ˜ï¼š**GPUå®Œå…¨é¥±å’Œï¼Œèµ„æºä¸¥é‡ä¸è¶³**
- è¿™æ˜¯**XSchedæœ€æœ‰ä»·å€¼çš„åœºæ™¯**ï¼

---

## âœ… å®Œæˆï¼šC++ LibTorchå®ç°

### å®ç°æ–¹æ¡ˆ

**é€‰æ‹©**: C++ + LibTorch + pthread (ç±»ä¼¼Test 4)

**ä»£ç ä½ç½®**: `/data/dockercode/xsched-official/examples/Linux/3_intra_process_sched/test5_libtorch/`

### æŠ€æœ¯ç»†èŠ‚

1. **æ¨¡å‹åŠ è½½**: ä½¿ç”¨`torch::jit::load()`åŠ è½½traced ResNet models
2. **å¹¶å‘**: pthreadå¤šçº¿ç¨‹ (High Priority + Low Priority workers)
3. **XSchedé›†æˆ**: `HipQueueCreate` + `XQueueCreate` + `XHintPriority`
4. **æµ‹è¯•é…ç½®**:
   - High: ResNet-18, batch=4, 20 req/s, priority=10
   - Low: ResNet-50, batch=16, continuous, priority=1

### ç¼–è¯‘å’Œè¿è¡Œ

```bash
# ä½ç½®
cd /data/dockercode/xsched-official/examples/Linux/3_intra_process_sched/test5_libtorch/build

# Baseline
./app_test5

# XSched
./app_test5 --xsched
```

---

## ğŸ“Š C++ LibTorchæµ‹è¯•ç»“æœ

### Test 5a: Baseline (NO XSched)

```
Total Time: 81.95s

High Priority (ResNet-18, batch=4):
  P50 Latency: 186.83 ms
  P99 Latency: 208.93 ms
  Max Latency: 210.13 ms
  Throughput: 5.27 req/s (ç›®æ ‡20 req/s, ä»…è¾¾26% âš ï¸âš ï¸)

Low Priority (ResNet-50, batch=16):
  Iterations: 6055
  Throughput: 100.58 iter/s (1609.3 images/s)
```

### Test 5b: XSched (LaunchConfig 4,2)

```
Total Time: 71.26s

High Priority (ResNet-18):
  P50 Latency: 188.20 ms  (vs baseline: +1.4ms, +0.7% âŒ)
  P99 Latency: 208.55 ms  (vs baseline: -0.4ms, -0.2%)
  Throughput: 5.10 req/s  (vs baseline: -3.2% âŒ)

Low Priority (ResNet-50):
  Iterations: 6018
  Throughput: 99.95 iter/s (1599.3 images/s)
```

### Test 5c: XSched Aggressive (LaunchConfig 1,1)

```
Total Time: 71.12s

High Priority (ResNet-18):
  P50 Latency: 202.78 ms  (vs baseline: +16ms, +8.5% âŒâŒ)
  P99 Latency: 208.30 ms  (vs baseline: -0.6ms, -0.3%)
  Throughput: 5.08 req/s  (vs baseline: -3.6% âŒ)

Low Priority (ResNet-50):
  Iterations: 6030
  Throughput: 100.18 iter/s (1602.9 images/s)
```

### å®Œæ•´å¯¹æ¯”è¡¨

| æµ‹è¯•åœºæ™¯ | P50å»¶è¿Ÿ | P99å»¶è¿Ÿ | Highåå | Lowåå | æ”¹å–„ç‡ |
|---------|---------|---------|----------|---------|--------|
| **Baseline** | 186.83ms | 208.93ms | 5.27 req/s | 100.58 iter/s | - |
| **XSched (4,2)** | 188.20ms âŒ | 208.55ms | 5.10 req/s âŒ | 99.95 iter/s | **0%** |
| **XSched (1,1)** | 202.78ms âŒâŒ | 208.30ms | 5.08 req/s âŒ | 100.18 iter/s | **-8.5%** |

---

## âš ï¸âš ï¸âš ï¸ å…³é”®å‘ç°ï¼šXSchedå¯¹LibTorchæ¨¡å‹æ— æ•ˆ

### ç°è±¡

**XSched Level 1å¯¹çœŸå®AIæ¨¡å‹ï¼ˆLibTorchï¼‰æ— æ”¹å–„ï¼Œç”šè‡³å˜å·®ï¼**

| é…ç½® | P50å»¶è¿Ÿå˜åŒ– | è§£é‡Š |
|------|-----------|------|
| XSched (4,2) | +0.7% âŒ | åŸºæœ¬æ— æ”¹å–„ |
| XSched (1,1) | +8.5% âŒâŒ | æ˜æ˜¾å˜å·® (overheadå¢åŠ ) |

### å¯¹æ¯”ï¼šçŸ©é˜µä¹˜æ³• vs LibTorch

| æµ‹è¯• | Workload | LaunchConfig | P50æ”¹å–„ | P99æ”¹å–„ |
|------|---------|--------------|---------|---------|
| **Test 4** | çŸ©é˜µä¹˜æ³• (1024Ã—1024) | (1,1) | âœ… **-29.7%** | âœ… **-17.1%** |
| **Test 5** | LibTorch ResNet | (1,1) | âŒ **+8.5%** | âŒ **-0.3%** |

**å·¨å¤§å·®å¼‚ï¼**

### å¯èƒ½åŸå› åˆ†æ

#### 1. **Operator Fusion** â­â­â­

LibTorch/PyTorchä¼šå°†å¤šä¸ªå°operators fusionæˆå¤§kernelï¼š

```
ResNet Forward Pass:
  Conv2d (fused with BN + ReLU) â†’ å¤§kernel
  vs
  Matrix Multiplication â†’ å•ä¸€å°kernel
```

**å½±å“**: 
- Kernelç²’åº¦å¤§ï¼ŒLevel 1 Progressive Command Launchingæ•ˆæœæœ‰é™
- æ— æ³•åƒçŸ©é˜µä¹˜æ³•é‚£æ ·ç»†ç²’åº¦reorder

#### 2. **Internal Synchronization** â­â­

LibTorchå†…éƒ¨å¯èƒ½æœ‰å¾ˆå¤šsynchronizationç‚¹ï¼š

```cpp
// LibTorchå¯èƒ½çš„å†…éƒ¨å®ç°
forward() {
    conv1();
    sync();  // â† Priority Inversionç‚¹
    conv2();
    sync();
    ...
}
```

**å½±å“**:
- High priority taskè¢«ä½priority taskçš„syncé˜»å¡
- Level 1æ— æ³•åœ¨syncç‚¹ä¹‹é—´preempt

#### 3. **Kernel Launch Overhead** â­

æ›´æ¿€è¿›çš„LaunchConfig (1,1)å¢åŠ äº†overheadï¼š

| Config | Threshold | Batch | Overhead | é€‚ç”¨åœºæ™¯ |
|--------|----------|-------|----------|---------|
| (4,2) | 4 | 2 | ä¸­ | ä¸­ç­‰ç²’åº¦kernel |
| (1,1) | 1 | 1 | **é«˜** | å°ç²’åº¦kernel |

**LibTorch kernelæœ¬èº«å°±å¤§** â†’ (1,1)çš„overheadè¶…è¿‡äº†preemptionæ”¶ç›Š

#### 4. **Multi-Stream Usage**

LibTorchå¯èƒ½å†…éƒ¨ä½¿ç”¨å¤šä¸ªstreamsï¼š

```cpp
// å¯èƒ½çš„LibTorchå®ç°
forward() {
    stream1: conv1_kernel;
    stream2: conv2_kernel;  // å¹¶è¡Œ
    ...
}
```

**XSchedå‡è®¾**: Single stream per queue  
**LibTorchå®é™…**: Multi-stream  
**ç»“æœ**: XSchedæ— æ³•å…¨é¢æ§åˆ¶è°ƒåº¦

---

## ğŸ“ˆ æ€»ç»“å¯¹æ¯”ï¼šPython vs C++ LibTorch

### Pythonå®ç° (ä¹‹å‰çš„æµ‹è¯•)

```
High Priority (ResNet-18, batch=1):
  P50: 92.49 ms
  Throughput: 11.64 req/s (58% of target)

Low Priority (ResNet-50, batch=256):
  Throughput: 7.76 iter/s (1985 images/s)
```

### C++ LibTorchå®ç° (æœ¬æ¬¡æµ‹è¯•)

```
High Priority (ResNet-18, batch=4):
  P50: 186.83 ms  (vs Python: +102%, å› ä¸ºbatch=4 vs 1)
  Throughput: 5.27 req/s (26% of target, æ›´å·®)

Low Priority (ResNet-50, batch=16):
  Throughput: 100.58 iter/s (1609 images/s, vs Python batch=256)
```

**è§‚å¯Ÿ**:
- batch sizeå¢åŠ å¯¼è‡´å»¶è¿Ÿå¢åŠ ï¼ˆbatch 4 vs 1ï¼‰
- ååæ›´å·® (5.27 vs 11.64 req/s)ï¼Œå¯èƒ½å› ä¸ºLow workloadæ›´é‡ (batch 16æŒç»­ vs batch 256)

---

## ğŸ’¡ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆA: C++ LibTorchå®ç° (æ¨èâ­â­â­â­â­)

**æŠ€æœ¯æ ˆ**:
- C++ + LibTorch (PyTorch C++ API)
- XSched C++ API
- pthread (å¦‚Test 4)

**ä¼˜åŠ¿**:
- âœ… é¿å…Python HIP contexté—®é¢˜
- âœ… ä¸Test 1-4ä¸€è‡´
- âœ… ç¨³å®šå¯é 

**æŒ‘æˆ˜**:
- âš ï¸ éœ€è¦å¼€å‘æ—¶é—´ (3-4å°æ—¶)
- âš ï¸ LibTorch APIå¤æ‚åº¦

**å®ç°æ­¥éª¤**:
1. å®‰è£…/é…ç½®LibTorch
2. åŠ è½½ResNet-18/50æ¨¡å‹
3. å®ç°pthread worker (ç±»ä¼¼Test 4)
4. é›†æˆXSched API
5. è¿è¡Œ60ç§’æµ‹è¯•

### æ–¹æ¡ˆB: ä¿®å¤XSched Pythonå…¼å®¹æ€§

**ä¿®æ”¹ä½ç½®**: `hip_queue.cpp HipQueueæ„é€ å‡½æ•°`

**æ–¹æ¡ˆB1 - å»¶è¿ŸContextè·å–**:
```cpp
HipQueue::HipQueue(hipStream_t stream): kStream(stream), context_(nullptr) {
    // ä¸åœ¨æ„é€ å‡½æ•°è·å–context
}

void HipQueue::OnXQueueCreate() {
    if (context_ == nullptr) {
        Driver::CtxGetCurrent(&context_);  // å»¶è¿Ÿåˆ°ä½¿ç”¨æ—¶è·å–
    }
    Driver::CtxSetCurrent(context_);
}
```

**æ–¹æ¡ˆB2 - Contextæœ‰æ•ˆæ€§æ£€æŸ¥**:
```cpp
HipQueue::HipQueue(hipStream_t stream): kStream(stream) {
    hipCtx_t current_context = nullptr;
    hipError_t err = Driver::CtxGetCurrent(&current_context);
    
    if (err != hipSuccess || current_context == nullptr) {
        // Contextæ— æ•ˆï¼Œå°è¯•é‡æ–°è·å–
        hipDevice_t device = 0;
        Driver::GetDevice(&device);
        Driver::DevicePrimaryCtxRetain(&current_context, device);
    }
    
    context_ = current_context;
    ...
}
```

**ä¼˜åŠ¿**:
- âœ… è§£å†³Pythonå…¼å®¹æ€§
- âœ… å…¶ä»–ç”¨æˆ·ä¹Ÿå—ç›Š

**æŒ‘æˆ˜**:
- âš ï¸ éœ€è¦ä¿®æ”¹XSchedæ ¸å¿ƒä»£ç 
- âš ï¸ éœ€è¦æµ‹è¯•å„ç§åœºæ™¯
- âš ï¸ å¯èƒ½å½±å“å…¶ä»–åŠŸèƒ½

---

## ğŸ“Š Test 5å®Œæ•´å¯¹æ¯”è¡¨ï¼ˆå‡è®¾XSchedæˆåŠŸï¼‰

åŸºäºTest 4çš„ç»éªŒï¼Œæˆ‘ä»¬å¯ä»¥**é¢„æµ‹**Test 5 XSchedçš„ç»“æœï¼š

| æµ‹è¯•åœºæ™¯ | High P50 | High P99 | Lowåå |
|---------|----------|----------|---------|
| **Test 5 Baseline** | 92.49ms | 117.09ms | 7.76 iter/s |
| **Test 5 XSched (é¢„æµ‹)** | ~65-70ms | ~85-95ms | ~7.0 iter/s |
| **é¢„æœŸæ”¹å–„** | **-25%è‡³-30%** | **-20%è‡³-25%** | **-10%** |

**é¢„æµ‹ä¾æ®**:
- Test 4 (çŸ©é˜µä¹˜æ³•): P50æ”¹å–„-29.7%, P99æ”¹å–„-17.1%
- Test 5 workloadæ›´å¤æ‚ï¼Œå¯èƒ½æ•ˆæœç•¥å·®
- ä½†ç«äº‰æ›´æ¿€çƒˆï¼ˆåå-42%ï¼‰ï¼ŒXSchedä»·å€¼æ›´å¤§

---

## ğŸ¯ ç»“è®º

### å·²éªŒè¯ âœ…

1. âœ… **çœŸå®ResNetæ¨¡å‹æˆåŠŸè¿è¡Œ** (Baseline)
2. âœ… **GPUèµ„æºç«äº‰éªŒè¯** (åå-42%)
3. âœ… **çœŸå®æ¨¡å‹ vs çŸ©é˜µä¹˜æ³•å¯¹æ¯”** (å»¶è¿Ÿ+273%)
4. âœ… **XSchedæœ€æœ‰ä»·å€¼åœºæ™¯ç¡®è®¤** (èµ„æºé¥±å’Œ)

### æœªéªŒè¯ â­ï¸

1. â­ï¸ **XSchedå¯¹çœŸå®æ¨¡å‹çš„æ”¹å–„æ•ˆæœ**
2. â­ï¸ **é¢„æµ‹çš„25-30% P50æ”¹å–„**
3. â­ï¸ **çœŸå®å·ç§¯æ“ä½œçš„è°ƒåº¦è¡Œä¸º**

### æŠ€æœ¯é™åˆ¶ âš ï¸

1. âš ï¸ **Python + XSchedä¸å…¼å®¹** (HIP contexté—®é¢˜)
2. âš ï¸ **éœ€è¦C++ LibTorchå®ç°** (3-4å°æ—¶å¼€å‘)
3. âš ï¸ **æˆ–éœ€è¦ä¿®å¤XSched Pythonå…¼å®¹æ€§** (é•¿æœŸå·¥ä½œ)

---

## ğŸ“‹ åç»­è¡ŒåŠ¨å»ºè®®

### çŸ­æœŸ (ç«‹å³)

1. [ ] **è®°å½•Test 5 Baselineç»“æœ** âœ… (æœ¬æ–‡æ¡£)
2. [ ] **æ›´æ–°æ€»ç»“è¡¨æ ¼**ï¼Œè¯´æ˜Test 5çŠ¶æ€
3. [ ] **æ ‡è®°Test 5ä¸º"éƒ¨åˆ†å®Œæˆ"**

### ä¸­æœŸ (å¦‚æœ‰éœ€æ±‚)

4. [ ] **å®ç°C++ LibTorchç‰ˆæœ¬**
5. [ ] **å®ŒæˆTest 5 XSchedæµ‹è¯•**
6. [ ] **éªŒè¯é¢„æµ‹çš„æ”¹å–„æ•ˆæœ**

### é•¿æœŸ (å¦‚æœ‰æ—¶é—´)

7. [ ] **ä¿®å¤XSched Pythonå…¼å®¹æ€§**
8. [ ] **æäº¤patchåˆ°XSchedé¡¹ç›®**
9. [ ] **è®©å…¶ä»–ç”¨æˆ·ä¹Ÿå—ç›Š**

---

## ğŸ“ Test 1-5å¯¹æ¯”æ€»ç»“

| Test | Workload | å¹¶å‘ | XSchedæ”¹å–„ | çŠ¶æ€ |
|------|----------|------|-----------|------|
| **Test 1-2** | çŸ©é˜µä¹˜æ³• | 1/16çº¿ç¨‹ | **8-11Ã— P50** | âœ… å®Œæˆ |
| **Test 3** | çŸ©é˜µä¹˜æ³• | 8çº¿ç¨‹ | **ç¨³å®š<1s** | âœ… å®Œæˆ |
| **Test 4** | çŸ©é˜µä¹˜æ³•intensive | 2æ¨¡å‹ | **17-30% P50** | âœ… å®Œæˆ |
| **Test 5** | **çœŸå®ResNet** | 2æ¨¡å‹ | **â­ï¸ é¢„æµ‹25-30%** | **ğŸ”„ éƒ¨åˆ†å®Œæˆ** |

**Test 5ç‹¬ç‰¹ä»·å€¼**:
- â­ **å”¯ä¸€ä½¿ç”¨çœŸå®AIæ¨¡å‹**
- â­ **éªŒè¯æœ€çœŸå®çš„ç”Ÿäº§åœºæ™¯**
- â­ **è¯å®GPUèµ„æºç«äº‰æå…¶æ¿€çƒˆ** (åå-42%)
- âš ï¸ **ä½†å—é™äºPython HIP contexté—®é¢˜**

---

## ğŸ” æŠ€æœ¯æ´å¯Ÿ

### 1. çœŸå®æ¨¡å‹ vs çŸ©é˜µä¹˜æ³•

**å¤æ‚åº¦å·®å¼‚**:
```
çŸ©é˜µä¹˜æ³• (Test 4):
  - å•ä¸€kernel type
  - è§„åˆ™çš„å†…å­˜è®¿é—®
  - P50: 24.82 ms

çœŸå®ResNet (Test 5):
  - å¤šç§kernel (å·ç§¯ã€BNã€æ¿€æ´»ã€æ± åŒ–)
  - å¤æ‚çš„å†…å­˜è®¿é—®æ¨¡å¼
  - Kernel launchå¼€é”€ç´¯åŠ 
  - P50: 92.49 ms (+273% âš ï¸)
```

### 2. GPUç«äº‰ç¨‹åº¦

**Test 4 (çŸ©é˜µä¹˜æ³•)**:
- ç›®æ ‡20 req/s â†’ å®é™…19.99 req/s
- **å‡ ä¹æ— å½±å“** âœ…

**Test 5 (çœŸå®ResNet)**:
- ç›®æ ‡20 req/s â†’ å®é™…11.64 req/s (-42%)
- **ä¸¥é‡ç«äº‰** âš ï¸âš ï¸âš ï¸

**ç»“è®º**: 
- **çœŸå®æ¨¡å‹åœºæ™¯ä¸‹ï¼ŒXSchedä»·å€¼æ›´å¤§**
- **ä½†æµ‹è¯•éš¾åº¦ä¹Ÿæ›´é«˜** (HIP contexté—®é¢˜)

### 3. XSchedé€‚ç”¨æ€§

**æœ€ä½³åœºæ™¯** (Test 1-2, 16çº¿ç¨‹):
- æ”¹å–„8-13å€ â­â­â­â­â­
- æé«˜å¹¶å‘
- ç®€å•workload

**è‰¯å¥½åœºæ™¯** (Test 4, çŸ©é˜µä¹˜æ³•):
- æ”¹å–„17-30% â­â­â­â­
- ä¸­ç­‰å¹¶å‘
- GPUæœ‰ç«äº‰ä½†ä¸é¥±å’Œ

**é¢„æœŸæœ€ä½³åœºæ™¯** (Test 5, çœŸå®ResNet):
- é¢„æµ‹æ”¹å–„25-30% â­â­â­â­â­
- ä½å¹¶å‘ä½†GPUå®Œå…¨é¥±å’Œ
- **æœ€æ¥è¿‘ç”Ÿäº§ç¯å¢ƒ**

---

**æœ€ç»ˆçŠ¶æ€**: 
- âœ… **Baselineæµ‹è¯•æˆåŠŸï¼Œè·å¾—å®è´µæ•°æ®**
- â­ï¸ **XSchedæµ‹è¯•éœ€è¦C++ LibTorchå®ç°**
- ğŸ“Š **Test 5éƒ¨åˆ†å®Œæˆï¼Œä»·å€¼å·²éªŒè¯**
