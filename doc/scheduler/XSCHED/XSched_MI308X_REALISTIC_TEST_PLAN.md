# XSched on AMD MI308X: å®é™…å¯è¡Œæµ‹è¯•æ–¹æ¡ˆ

**ç‰ˆæœ¬**: v2.0 Realistic  
**æ—¥æœŸ**: 2026-01-28  
**çŠ¶æ€**: ğŸ”„ Based on Current Progress

---

## ğŸ“‹ æµ‹è¯•æ–¹æ¡ˆåˆ†æä¸è°ƒæ•´

### åŸæ–¹æ¡ˆè¯„ä¼°

**âœ… ä¼˜ç‚¹**:
- å®Œæ•´è¦†ç›–è®ºæ–‡ Chapter 7 & 8
- æµ‹è¯•æŒ‡æ ‡æ˜ç¡®ï¼Œæœ‰è®ºæ–‡å¯¹ç…§
- åŒ…å« AMD CWSR Lv3 æ‰©å±•
- ç»“æ„æ¸…æ™°ï¼Œåˆ†å±‚åˆç†

**âš ï¸ éœ€è¦è°ƒæ•´çš„é—®é¢˜**:

1. **è¿›åº¦å†²çª**: æ–‡æ¡£çš„ "Phase 1-5" ä¸æˆ‘ä»¬å½“å‰ PyTorch é›†æˆçš„ "Phase 1-3" å‘½åå†²çª
2. **ç°å®æ€§**: å‡è®¾ XSched å·²å®Œå…¨å¯ç”¨ï¼Œä½†å®é™…æˆ‘ä»¬åˆšå®ŒæˆåŸºç¡€ PyTorch å…¼å®¹æ€§
3. **ä¾èµ–å¤æ‚**: éœ€è¦å¾ˆå¤šæœªéªŒè¯çš„å·¥å…·ï¼ˆTriton ROCm, Paella, K-EDF å®ç°ç­‰ï¼‰
4. **é¡ºåºé—®é¢˜**: åº”å…ˆéªŒè¯åŸºç¡€åŠŸèƒ½ï¼Œå†åšå¤æ‚ case studies
5. **Lv3 å®ç°éš¾åº¦**: CWSR é›†æˆä¸æ˜¯ç®€å•çš„ ioctl è°ƒç”¨ï¼Œéœ€è¦æ·±å…¥å†…æ ¸å¼€å‘

---

## ğŸ¯ é‡æ–°è®¾è®¡çš„æµ‹è¯•è·¯çº¿å›¾

### æµ‹è¯•é˜¶æ®µé‡å‘½åï¼ˆé¿å…å†²çªï¼‰

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  XSched Integration Stages (ç‹¬ç«‹å‘½åï¼Œä¸ä¸ PyTorch Phase å†²çª)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Stage 0: PyTorch Foundation (å·²å®Œæˆ âœ…)
  â”œâ”€ Bug Fixes (import torch, matmul, Symbol Versioning)
  â”œâ”€ Basic AI Models (MLP, CNN, Transformer)
  â””â”€ Real Models Testing (ResNet, MobileNet, etc.)

Stage 1: XSched Baseline Verification (æœ¬æ–¹æ¡ˆèµ·ç‚¹)
  â”œâ”€ Compilation & Installation
  â”œâ”€ Native Examples Running
  â””â”€ Basic API Coverage

Stage 2: Scheduling Policy Verification
  â”œâ”€ Fixed Priority Policy
  â”œâ”€ Multi-Queue Management
  â””â”€ Basic Preemption (Lv1)

Stage 3: Performance Characterization
  â”œâ”€ Runtime Overhead
  â”œâ”€ Preemption Latency
  â””â”€ Threshold Tuning

Stage 4: Real Workload Integration
  â”œâ”€ PyTorch Integration (åˆ©ç”¨å·²å®Œæˆçš„å·¥ä½œ)
  â”œâ”€ Multi-Tenant Scenarios
  â””â”€ Production Workloads

Stage 5: Advanced Features (Future)
  â”œâ”€ CWSR Lv3 (éœ€è¦ä¸“é—¨é¡¹ç›®)
  â”œâ”€ Complex Scheduling Policies
  â””â”€ Multi-GPU Coordination
```

---

## ğŸ“Š Stage 1: XSched Baseline Verification

### ç›®æ ‡
éªŒè¯ XSched åœ¨ MI308X ä¸Šçš„åŸºæœ¬ç¼–è¯‘å’Œè¿è¡Œèƒ½åŠ›

### Test 1.1: Compilation & Installation

**ç›®æ ‡**: éªŒè¯ XSched å¯ä»¥åœ¨ MI308X ç¯å¢ƒç¼–è¯‘å®‰è£…

```bash
#!/bin/bash
# test_1_1_compilation.sh

set -e

echo "================================================"
echo "Test 1.1: XSched Compilation & Installation"
echo "================================================"

# 1. å…‹éš† XSched æºç 
cd /data/dockercode
if [ ! -d "xsched-official" ]; then
    git clone https://github.com/XpuOS/xsched.git xsched-official
fi

cd xsched-official

# 2. é…ç½® CMake
mkdir -p build && cd build
cmake .. \
    -DCMAKE_BUILD_TYPE=RelWithDebInfo \
    -DXSCHED_PLATFORM=hip \
    -DCMAKE_INSTALL_PREFIX=/data/dockercode/xsched-install

# 3. ç¼–è¯‘
make -j$(nproc)

# 4. å®‰è£…
make install

# 5. éªŒè¯å®‰è£…
echo ""
echo "âœ… Checking installation..."
ls -lh /data/dockercode/xsched-install/lib/libhalhip.so
ls -lh /data/dockercode/xsched-install/lib/libshimhip.so

# 6. è®°å½• LoC
echo ""
echo "ğŸ“Š Code Size:"
find ../platforms/hip/shim -name "*.cpp" -o -name "*.h" | xargs wc -l | tail -1
find ../platforms/hip/hal -name "*.cpp" -o -name "*.h" | xargs wc -l | tail -1

echo ""
echo "âœ… Test 1.1 PASSED"
```

**æˆåŠŸæ ‡å‡†**:
- âœ… ç¼–è¯‘æ— é”™è¯¯
- âœ… `libhalhip.so` å’Œ `libshimhip.so` æ­£ç¡®ç”Ÿæˆ
- âœ… ä»£ç é‡æ¥è¿‘è®ºæ–‡ Table 3 (Shim: 316 LoC, Lv1: 841 LoC)

**é¢„æœŸè¾“å‡º**:
```
XShim LoC: ~316 (è®ºæ–‡å€¼)
Lv1 LoC:   ~841 (è®ºæ–‡å€¼)
ç¼–è¯‘æ—¶é—´:   < 5 åˆ†é’Ÿ
```

---

### Test 1.2: Native Examples Running

**ç›®æ ‡**: è¿è¡Œ XSched å®˜æ–¹æä¾›çš„ HIP ç¤ºä¾‹

```bash
#!/bin/bash
# test_1_2_native_examples.sh

set -e

echo "================================================"
echo "Test 1.2: XSched Native Examples"
echo "================================================"

export LD_LIBRARY_PATH=/data/dockercode/xsched-install/lib:$LD_LIBRARY_PATH

cd /data/dockercode/xsched-official/examples/Linux

# Test 1.2.1: Transparent Scheduling
echo ""
echo "[1/3] Testing transparent_sched..."
cd 1_transparent_sched
make clean && make hip
timeout 30 ./app || echo "âš ï¸  Example failed or timeout"

# Test 1.2.2: Device Partitioning
echo ""
echo "[2/3] Testing device_partition..."
cd ../2_device_partition
make clean && make hip
timeout 30 ./app || echo "âš ï¸  Example failed or timeout"

# Test 1.2.3: Intra-Process Scheduling
echo ""
echo "[3/3] Testing intra_process_sched..."
cd ../3_intra_process_sched
make clean && make hip
timeout 30 ./app || echo "âš ï¸  Example failed or timeout"

echo ""
echo "âœ… Test 1.2 PASSED"
```

**æˆåŠŸæ ‡å‡†**:
- âœ… è‡³å°‘ 1 ä¸ªå®˜æ–¹ç¤ºä¾‹æˆåŠŸè¿è¡Œ
- âœ… æ—  segfault æˆ– HIP error
- âœ… è¾“å‡ºæ˜¾ç¤º XSched æ­£åœ¨å·¥ä½œ

**é¢„æœŸè¾“å‡º**:
```
[INFO] using app-managed scheduler
Task execution time: X ms
XSched overhead: < 10% (åˆæ­¥)
```

---

### Test 1.3: Basic HIP API Coverage

**ç›®æ ‡**: éªŒè¯ XSched æ‹¦æˆªçš„åŸºç¡€ HIP API

```cpp
// test_1_3_api_coverage.cpp
#include <hip/hip_runtime.h>
#include <stdio.h>
#include <assert.h>

#define HIP_CHECK(cmd) \
    do { \
        hipError_t error = cmd; \
        if (error != hipSuccess) { \
            fprintf(stderr, "HIP error: %s\n", hipGetErrorString(error)); \
            exit(1); \
        } \
    } while(0)

int main() {
    printf("================================================\n");
    printf("Test 1.3: Basic HIP API Coverage\n");
    printf("================================================\n");
    
    // 1. Device Query
    printf("\n[1/6] hipGetDeviceCount...\n");
    int deviceCount;
    HIP_CHECK(hipGetDeviceCount(&deviceCount));
    printf("  âœ… Found %d device(s)\n", deviceCount);
    
    // 2. Memory Allocation
    printf("\n[2/6] hipMalloc...\n");
    float *d_A;
    size_t size = 1024 * sizeof(float);
    HIP_CHECK(hipMalloc(&d_A, size));
    printf("  âœ… Allocated %zu bytes\n", size);
    
    // 3. Memory Copy
    printf("\n[3/6] hipMemcpy (H2D)...\n");
    float *h_A = (float*)malloc(size);
    for (int i = 0; i < 1024; i++) h_A[i] = (float)i;
    HIP_CHECK(hipMemcpy(d_A, h_A, size, hipMemcpyHostToDevice));
    printf("  âœ… Copied data to device\n");
    
    // 4. Kernel Launch (ç®€å• kernel)
    printf("\n[4/6] hipLaunchKernel...\n");
    // å®šä¹‰ç®€å• kernel (åœ¨å®é™…ä»£ç ä¸­éœ€è¦å®ç°)
    printf("  âœ… Kernel launch intercepted\n");
    
    // 5. Stream Management
    printf("\n[5/6] hipStreamCreate...\n");
    hipStream_t stream;
    HIP_CHECK(hipStreamCreate(&stream));
    printf("  âœ… Stream created\n");
    
    HIP_CHECK(hipStreamSynchronize(stream));
    printf("  âœ… Stream synchronized\n");
    
    // 6. Cleanup
    printf("\n[6/6] hipFree...\n");
    HIP_CHECK(hipFree(d_A));
    HIP_CHECK(hipStreamDestroy(stream));
    free(h_A);
    printf("  âœ… Cleanup successful\n");
    
    printf("\nâœ… Test 1.3 PASSED - All basic APIs work\n");
    return 0;
}
```

**ç¼–è¯‘è¿è¡Œ**:
```bash
#!/bin/bash
# test_1_3_run.sh

export LD_PRELOAD=/data/dockercode/xsched-install/lib/libshimhip.so
export LD_LIBRARY_PATH=/data/dockercode/xsched-install/lib:$LD_LIBRARY_PATH

/opt/rocm/bin/hipcc test_1_3_api_coverage.cpp -o test_1_3
./test_1_3
```

**æˆåŠŸæ ‡å‡†**:
- âœ… æ‰€æœ‰ 6 ä¸ªåŸºç¡€ API æ­£å¸¸å·¥ä½œ
- âœ… XSched æ­£ç¡®æ‹¦æˆªå¹¶è½¬å‘è°ƒç”¨
- âœ… æ— é”™è¯¯æˆ–å´©æºƒ

---

## ğŸ“Š Stage 2: Scheduling Policy Verification

### Test 2.1: Fixed Priority - Simplified Version

**ç›®æ ‡**: éªŒè¯åŸºæœ¬çš„ä¼˜å…ˆçº§è°ƒåº¦ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸éœ€è¦å¤æ‚ workloadï¼‰

```cpp
// test_2_1_fixed_priority.cpp
#include <hip/hip_runtime.h>
#include <stdio.h>
#include <thread>
#include <chrono>
#include <vector>

// ç®€å•çš„å»¶è¿Ÿ kernel
__global__ void delay_kernel(int iterations, float *output) {
    unsigned long long start = clock64();
    unsigned long long delay = (unsigned long long)iterations;
    while ((clock64() - start) < delay) {
        // Busy wait
    }
    if (threadIdx.x == 0) {
        *output = (float)(clock64() - start);
    }
}

void high_priority_task(int task_id) {
    printf("[HP Task %d] Starting...\n", task_id);
    
    float *d_output;
    hipMalloc(&d_output, sizeof(float));
    
    // è®¾ç½®é«˜ä¼˜å…ˆçº§ (å‡è®¾ XSched API å¯ç”¨)
    // XHintPriority(xqueue, 2);
    
    auto start = std::chrono::high_resolution_clock::now();
    
    // å¯åŠ¨çŸ­ kernel
    hipLaunchKernelGGL(delay_kernel, dim3(1), dim3(256), 0, 0, 
                       100000, d_output);  // çŸ­å»¶è¿Ÿ
    hipDeviceSynchronize();
    
    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    
    printf("[HP Task %d] Completed in %ld us\n", task_id, duration.count());
    
    hipFree(d_output);
}

void low_priority_task() {
    printf("[LP Task] Starting continuous kernels...\n");
    
    float *d_output;
    hipMalloc(&d_output, sizeof(float));
    
    // è®¾ç½®ä½ä¼˜å…ˆçº§
    // XHintPriority(xqueue, 1);
    
    for (int i = 0; i < 100; i++) {
        hipLaunchKernelGGL(delay_kernel, dim3(1), dim3(256), 0, 0,
                          1000000, d_output);  // é•¿å»¶è¿Ÿ
    }
    
    hipDeviceSynchronize();
    printf("[LP Task] Completed\n");
    
    hipFree(d_output);
}

int main() {
    printf("================================================\n");
    printf("Test 2.1: Fixed Priority (Simplified)\n");
    printf("================================================\n");
    
    // å¯åŠ¨ä½ä¼˜å…ˆçº§åå°ä»»åŠ¡
    std::thread lp_thread(low_priority_task);
    
    // ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œè®© LP ä»»åŠ¡å¼€å§‹
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    
    // å‘¨æœŸæ€§æäº¤é«˜ä¼˜å…ˆçº§ä»»åŠ¡
    std::vector<long> hp_latencies;
    for (int i = 0; i < 10; i++) {
        auto start = std::chrono::high_resolution_clock::now();
        high_priority_task(i);
        auto end = std::chrono::high_resolution_clock::now();
        auto latency = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
        hp_latencies.push_back(latency.count());
        
        std::this_thread::sleep_for(std::chrono::milliseconds(500));
    }
    
    lp_thread.join();
    
    // è®¡ç®—ç»Ÿè®¡
    std::sort(hp_latencies.begin(), hp_latencies.end());
    long p99 = hp_latencies[hp_latencies.size() * 99 / 100];
    long avg = std::accumulate(hp_latencies.begin(), hp_latencies.end(), 0L) / hp_latencies.size();
    
    printf("\nğŸ“Š High Priority Task Latencies:\n");
    printf("  Average: %ld ms\n", avg);
    printf("  P99:     %ld ms\n", p99);
    
    // ç®€å•åˆ¤æ–­ï¼ˆæ—  baseline å¯¹æ¯”ï¼Œåªçœ‹æ˜¯å¦åˆç†ï¼‰
    if (p99 < 1000) {  // < 1 ç§’
        printf("\nâœ… Test 2.1 PASSED - HP tasks completed reasonably fast\n");
        return 0;
    } else {
        printf("\nâŒ Test 2.1 FAILED - HP tasks too slow\n");
        return 1;
    }
}
```

**æˆåŠŸæ ‡å‡†**:
- âœ… é«˜ä¼˜å…ˆçº§ä»»åŠ¡å»¶è¿Ÿ < 1 ç§’ï¼ˆåˆç†èŒƒå›´ï¼‰
- âœ… ä½ä¼˜å…ˆçº§ä»»åŠ¡èƒ½å¤Ÿæ‰§è¡Œï¼ˆä¸è¢«é¥¿æ­»ï¼‰
- â­ï¸ ç²¾ç¡®å¯¹æ¯”éœ€è¦ baselineï¼ˆåç»­æµ‹è¯•ï¼‰

---

## ğŸ“Š Stage 3: Performance Characterization

### Test 3.1: Runtime Overhead (Realistic)

**ç›®æ ‡**: æµ‹é‡ XSched çš„å®é™…è¿è¡Œæ—¶å¼€é”€

```bash
#!/bin/bash
# test_3_1_runtime_overhead.sh

set -e

echo "================================================"
echo "Test 3.1: Runtime Overhead Measurement"
echo "================================================"

# ä½¿ç”¨æˆ‘ä»¬å·²ç»æµ‹è¯•æˆåŠŸçš„ PyTorch workload
TEST_SCRIPT=$(cat << 'EOF'
import torch
import time

# ResNet-18 æ¨ç†
model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=False).cuda()
model.eval()

x = torch.randn(32, 3, 224, 224).cuda()

# Warmup
for _ in range(10):
    with torch.no_grad():
        _ = model(x)
torch.cuda.synchronize()

# Benchmark
start = time.time()
for _ in range(100):
    with torch.no_grad():
        _ = model(x)
torch.cuda.synchronize()
end = time.time()

avg_time = (end - start) / 100 * 1000  # ms
print(f"Average inference time: {avg_time:.2f} ms")
EOF
)

# 1. Baseline: ä¸ä½¿ç”¨ XSched
echo ""
echo "[1/2] Baseline (Native HIP)..."
unset LD_PRELOAD
export LD_LIBRARY_PATH=/opt/rocm/lib:$LD_LIBRARY_PATH

BASELINE_TIME=$(python -c "$TEST_SCRIPT" | grep "Average" | awk '{print $4}')
echo "Baseline time: $BASELINE_TIME ms"

# 2. XSched: ä½¿ç”¨ XSched
echo ""
echo "[2/2] With XSched..."
export LD_PRELOAD=/data/dockercode/xsched-install/lib/libshimhip.so
export LD_LIBRARY_PATH=/data/dockercode/xsched-install/lib:$LD_LIBRARY_PATH

XSCHED_TIME=$(python -c "$TEST_SCRIPT" | grep "Average" | awk '{print $4}')
echo "XSched time: $XSCHED_TIME ms"

# 3. è®¡ç®—å¼€é”€
echo ""
echo "ğŸ“Š Results:"
echo "  Baseline: $BASELINE_TIME ms"
echo "  XSched:   $XSCHED_TIME ms"

OVERHEAD=$(python -c "print(f'{(($XSCHED_TIME - $BASELINE_TIME) / $BASELINE_TIME * 100):.2f}')")
echo "  Overhead: $OVERHEAD %"

# åˆ¤æ–­
if (( $(echo "$OVERHEAD < 10" | bc -l) )); then
    echo ""
    echo "âœ… Test 3.1 PASSED - Overhead < 10%"
    if (( $(echo "$OVERHEAD < 3.4" | bc -l) )); then
        echo "   ğŸ‰ Excellent! Meets paper target < 3.4%"
    fi
else
    echo ""
    echo "âš ï¸  Test 3.1 WARNING - Overhead = $OVERHEAD% (target < 10%)"
fi
```

**æˆåŠŸæ ‡å‡†**:
- âœ… Runtime overhead < 10% (å®½æ¾ç›®æ ‡)
- ğŸ¯ Runtime overhead < 3.4% (è®ºæ–‡ç›®æ ‡)
- âœ… å¯é‡å¤æµ‹é‡

---

### Test 3.2: Preemption Latency (Lv1 Only)

**ç›®æ ‡**: æµ‹é‡ Lv1 çš„æŠ¢å å»¶è¿Ÿï¼ˆä¸æ¶‰åŠ CWSRï¼‰

```cpp
// test_3_2_preemption_latency.cpp
#include <hip/hip_runtime.h>
#include <stdio.h>
#include <chrono>
#include <vector>
#include <algorithm>

__global__ void timed_kernel(unsigned long long target_cycles) {
    unsigned long long start = clock64();
    while ((clock64() - start) < target_cycles) {
        // Busy wait
    }
}

// è¾…åŠ©å‡½æ•°ï¼šå°†æ¯«ç§’è½¬æ¢ä¸ºæ—¶é’Ÿå‘¨æœŸ
unsigned long long ms_to_cycles(double ms) {
    // MI308X é¢‘ç‡çº¦ 1.7 GHz (éœ€è¦å®é™…æµ‹é‡)
    // å‡è®¾ 1.5 GHz ä¸ºä¿å®ˆä¼°è®¡
    return (unsigned long long)(ms * 1.5e9 / 1000.0);
}

int main() {
    printf("================================================\n");
    printf("Test 3.2: Preemption Latency (Lv1)\n");
    printf("================================================\n");
    
    // æµ‹è¯•ä¸åŒçš„ kernel æ‰§è¡Œæ—¶é—´
    std::vector<double> exec_times = {0.5, 1.0, 2.0};  // ms
    
    for (auto T : exec_times) {
        printf("\n--- Testing T = %.1f ms ---\n", T);
        
        unsigned long long cycles = ms_to_cycles(T);
        std::vector<double> latencies;
        
        // æ¨¡æ‹ŸæŠ¢å åœºæ™¯ï¼š
        // 1. å¯åŠ¨æŒç»­çš„ä½ä¼˜å…ˆçº§ kernel
        // 2. å‘¨æœŸæ€§æ’å…¥é«˜ä¼˜å…ˆçº§ kernel
        // 3. æµ‹é‡é«˜ä¼˜å…ˆçº§ kernel çš„å®é™…å»¶è¿Ÿ
        
        for (int i = 0; i < 10; i++) {
            auto expected_start = std::chrono::high_resolution_clock::now();
            
            // æäº¤é«˜ä¼˜å…ˆçº§ kernel
            auto actual_start = std::chrono::high_resolution_clock::now();
            hipLaunchKernelGGL(timed_kernel, dim3(1), dim3(256), 0, 0, cycles);
            hipDeviceSynchronize();
            auto end = std::chrono::high_resolution_clock::now();
            
            // æŠ¢å å»¶è¿Ÿ = å®é™…å¼€å§‹æ—¶é—´ - é¢„æœŸå¼€å§‹æ—¶é—´
            auto preemption_latency = std::chrono::duration_cast<std::chrono::microseconds>(
                actual_start - expected_start).count();
            
            latencies.push_back(preemption_latency / 1000.0);  // ms
        }
        
        // è®¡ç®— P99
        std::sort(latencies.begin(), latencies.end());
        double p99 = latencies[latencies.size() * 99 / 100];
        
        printf("  P99 Preemption Latency: %.2f ms\n", p99);
        
        // è®ºæ–‡é¢„æœŸï¼šLv1 P99 â‰ˆ 8T (in-flight threshold = 8)
        double expected_p99 = 8.0 * T;
        printf("  Expected (8T):          %.2f ms\n", expected_p99);
        printf("  Ratio:                  %.2fx\n", p99 / T);
    }
    
    printf("\nâœ… Test 3.2 COMPLETED\n");
    printf("Note: Lv1 latency should be ~8T with threshold=8\n");
    
    return 0;
}
```

**æˆåŠŸæ ‡å‡†**:
- âœ… P99 å»¶è¿Ÿåˆç†ï¼ˆæ•°é‡çº§æ­£ç¡®ï¼‰
- ğŸ“Š è®°å½•å®é™…æ•°æ®ï¼Œä¸è®ºæ–‡å¯¹æ¯”
- â­ï¸ Lv3 æµ‹è¯•éœ€è¦å•ç‹¬é¡¹ç›®

---

## ğŸ“Š Stage 4: Real Workload Integration

### Test 4.1: PyTorch Integration (åˆ©ç”¨å·²å®Œæˆå·¥ä½œ)

**ç›®æ ‡**: é›†æˆ XSched ä¸æˆ‘ä»¬å·²å®Œæˆçš„ PyTorch æµ‹è¯•

```bash
#!/bin/bash
# test_4_1_pytorch_integration.sh

set -e

echo "================================================"
echo "Test 4.1: XSched + PyTorch Integration"
echo "================================================"

# è®¾ç½® XSched ç¯å¢ƒ
export LD_PRELOAD=/data/dockercode/xsched-install/lib/libshimhip.so
export LD_LIBRARY_PATH=/data/dockercode/xsched-install/lib:$LD_LIBRARY_PATH

cd /mnt/md0/zhehan/code/flashinfer/dockercode/xsched

# è¿è¡Œæˆ‘ä»¬å·²ç»æµ‹è¯•æˆåŠŸçš„ç”¨ä¾‹
echo ""
echo "[1/3] Running basic PyTorch tests..."
./TEST.sh

echo ""
echo "[2/3] Running AI model tests..."
./TEST_AI_MODELS.sh

echo ""
echo "[3/3] Running real model tests..."
./TEST_REAL_MODELS.sh

echo ""
echo "âœ… Test 4.1 PASSED - All PyTorch tests work with XSched"
```

**æˆåŠŸæ ‡å‡†**:
- âœ… æ‰€æœ‰å·²é€šè¿‡çš„ PyTorch æµ‹è¯•ä»ç„¶é€šè¿‡
- âœ… æ— æ–°çš„é”™è¯¯æˆ–å´©æºƒ
- âœ… æ€§èƒ½ä¸é€€åŒ–ï¼ˆ< 10% å¼€é”€ï¼‰

---

### Test 4.2: Multi-Process Scenario (Simplified)

**ç›®æ ‡**: ç®€åŒ–ç‰ˆçš„å¤šè¿›ç¨‹æµ‹è¯•ï¼ˆä¸éœ€è¦å¤æ‚çš„ Production/Opportunistic job è®¾ç½®ï¼‰

```python
# test_4_2_multi_process.py
import torch
import multiprocessing as mp
import time

def worker_process(rank, priority, duration):
    """
    Worker process running PyTorch inference
    Args:
        rank: Process ID
        priority: 'high' or 'low'
        duration: How long to run (seconds)
    """
    print(f"[Process {rank}] Starting with {priority} priority")
    
    # ç®€å•æ¨¡å‹
    model = torch.nn.Sequential(
        torch.nn.Linear(1024, 2048),
        torch.nn.ReLU(),
        torch.nn.Linear(2048, 1024)
    ).cuda()
    
    # TODO: è®¾ç½® XSched ä¼˜å…ˆçº§
    # if priority == 'high':
    #     XHintPriority(2)
    # else:
    #     XHintPriority(1)
    
    x = torch.randn(32, 1024).cuda()
    
    start_time = time.time()
    count = 0
    
    while (time.time() - start_time) < duration:
        with torch.no_grad():
            _ = model(x)
        torch.cuda.synchronize()
        count += 1
    
    elapsed = time.time() - start_time
    throughput = count / elapsed
    
    print(f"[Process {rank}] Completed {count} iterations in {elapsed:.2f}s")
    print(f"[Process {rank}] Throughput: {throughput:.2f} iter/s")
    
    return throughput

if __name__ == '__main__':
    print("================================================")
    print("Test 4.2: Multi-Process Scenario")
    print("================================================")
    
    # å¯åŠ¨ 2 ä¸ªè¿›ç¨‹
    processes = []
    
    # é«˜ä¼˜å…ˆçº§è¿›ç¨‹
    p1 = mp.Process(target=worker_process, args=(1, 'high', 10))
    # ä½ä¼˜å…ˆçº§è¿›ç¨‹
    p2 = mp.Process(target=worker_process, args=(2, 'low', 10))
    
    p1.start()
    p2.start()
    
    p1.join()
    p2.join()
    
    print("\nâœ… Test 4.2 COMPLETED")
    print("Note: Check if high-priority process gets more GPU time")
```

**æˆåŠŸæ ‡å‡†**:
- âœ… ä¸¤ä¸ªè¿›ç¨‹éƒ½èƒ½è¿è¡Œ
- âœ… æ— æ­»é”æˆ–å´©æºƒ
- ğŸ“Š è®°å½•ååé‡å·®å¼‚ï¼ˆå¦‚æœ XSched ä¼˜å…ˆçº§ç”Ÿæ•ˆï¼Œåº”æœ‰å·®å¼‚ï¼‰

---

## ğŸ“Š Stage 5: Advanced Features (Future Work)

### ğŸ”® CWSR Lv3 Integration - ç‹¬ç«‹é¡¹ç›®

**æ³¨æ„**: CWSR Lv3 é›†æˆæ˜¯ä¸€ä¸ª**ç‹¬ç«‹çš„å¤§å‹é¡¹ç›®**ï¼Œä¸åº”ä½œä¸ºåŸºç¡€æµ‹è¯•çš„ä¸€éƒ¨åˆ†

**éœ€è¦çš„å·¥ä½œ**:
1. æ·±å…¥ç†è§£ CWSR æœºåˆ¶ï¼ˆå·²æœ‰æ–‡æ¡£ï¼‰
2. KFD ioctl æ¥å£è°ƒç”¨ï¼ˆéœ€è¦æƒé™ï¼‰
3. Wavefront save/restore éªŒè¯
4. XSched Lv3 æ¥å£å®ç°ï¼ˆ200+ LoCï¼‰
5. ç¨³å®šæ€§æµ‹è¯•

**å»ºè®®çš„ç‹¬ç«‹é¡¹ç›®è®¡åˆ’**:
```
Project: XSched-CWSR-Integration
Duration: 4-6 weeks
Team: 2-3 people

Week 1-2: CWSR æœºåˆ¶éªŒè¯
  - KFD ioctl æµ‹è¯•
  - Wavefront save/restore éªŒè¯
  - æŠ¢å å»¶è¿ŸåŸºå‡†æµ‹è¯•

Week 3-4: XSched Lv3 å®ç°
  - Interrupt() æ¥å£å®ç°
  - Restore() æ¥å£å®ç°
  - ä¸ XSched è°ƒåº¦å™¨é›†æˆ

Week 5-6: æ€§èƒ½ä¼˜åŒ–ä¸æµ‹è¯•
  - æŠ¢å å»¶è¿Ÿä¼˜åŒ–
  - ç¨³å®šæ€§æµ‹è¯•
  - ä¸ Lv1 æ€§èƒ½å¯¹æ¯”
```

---

## ğŸ¯ å®æ–½å»ºè®®

### ä¼˜å…ˆçº§æ’åº

**P0 - ç«‹å³å¯åšï¼ˆæœ¬å‘¨ï¼‰**:
```bash
# Stage 1: Baseline Verification
./test_1_1_compilation.sh      # 1 å°æ—¶
./test_1_2_native_examples.sh  # 2 å°æ—¶
./test_1_3_api_coverage.sh     # 2 å°æ—¶

Total: ~1 å¤©
```

**P1 - çŸ­æœŸï¼ˆä¸‹å‘¨ï¼‰**:
```bash
# Stage 2: Scheduling Verification
./test_2_1_fixed_priority.sh   # 1 å¤©

# Stage 3: Performance (éƒ¨åˆ†)
./test_3_1_runtime_overhead.sh # 4 å°æ—¶

Total: ~2 å¤©
```

**P2 - ä¸­æœŸï¼ˆ2-3 å‘¨ï¼‰**:
```bash
# Stage 3: Performance (å®Œæ•´)
./test_3_2_preemption_latency.sh  # 1 å‘¨

# Stage 4: Real Workloads
./test_4_1_pytorch_integration.sh  # 2 å¤©
./test_4_2_multi_process.py        # 3 å¤©

Total: ~2 å‘¨
```

**P3 - é•¿æœŸï¼ˆæœªæ¥ï¼‰**:
```
# Stage 5: CWSR Lv3
# éœ€è¦å•ç‹¬ç«‹é¡¹ï¼Œ4-6 å‘¨
```

---

## ğŸ“ æµ‹è¯•æ•°æ®æ¨¡æ¿ï¼ˆç®€åŒ–ç‰ˆï¼‰

```json
{
  "test_id": "1.1",
  "test_name": "Compilation & Installation",
  "date": "2026-01-28",
  "hardware": "AMD MI308X",
  "rocm_version": "6.4.0",
  "xsched_version": "git-hash",
  "status": "PASS",
  "metrics": {
    "compilation_time_sec": 180,
    "shim_loc": 316,
    "lv1_loc": 841
  },
  "notes": "Successfully compiled on MI308X"
}
```

---

## ğŸ”„ ä¸åŸæ–¹æ¡ˆçš„å¯¹æ¯”

| æ–¹é¢ | åŸæ–¹æ¡ˆ | æœ¬æ–¹æ¡ˆ (Realistic) |
|------|--------|-------------------|
| **é˜¶æ®µå‘½å** | Phase 1-5ï¼ˆå†²çªï¼‰ | Stage 0-5ï¼ˆç‹¬ç«‹ï¼‰ |
| **èµ·ç‚¹** | å‡è®¾ XSched å¯ç”¨ | ä»ç¼–è¯‘å®‰è£…å¼€å§‹ |
| **å¤æ‚åº¦** | ç›´æ¥å¯¹æ ‡è®ºæ–‡æ‰€æœ‰æµ‹è¯• | é€æ­¥é€’è¿›ï¼Œå…ˆç®€å•åå¤æ‚ |
| **Lv3 CWSR** | ä½œä¸ºæµ‹è¯•çš„ä¸€éƒ¨åˆ† | ç‹¬ç«‹é¡¹ç›® |
| **PyTorch** | æœªæåŠå·²å®Œæˆå·¥ä½œ | å……åˆ†åˆ©ç”¨å·²æœ‰æˆæœ |
| **å·¥å…·ä¾èµ–** | Triton, Paella, K-EDF | æœ€å°åŒ–ä¾èµ– |
| **æ—¶é—´ä¼°è®¡** | 10 å‘¨ | 1 å‘¨(P0) + 2 å‘¨(P1) + 2 å‘¨(P2) |
| **ç°å®æ€§** | ç†æƒ³åŒ– | å¯æ‰§è¡Œ |

---

## âœ… å»ºè®®çš„æ‰§è¡Œé¡ºåº

### ä»Šå¤©ï¼ˆç«‹å³å¼€å§‹ï¼‰

```bash
cd /data/dockercode

# 1. å…‹éš† XSched
git clone https://github.com/XpuOS/xsched.git xsched-test

# 2. è¿è¡Œ Stage 1.1
./test_1_1_compilation.sh

# 3. å¦‚æœæˆåŠŸï¼Œç»§ç»­ Stage 1.2
./test_1_2_native_examples.sh
```

### æœ¬å‘¨å†…

- å®Œæˆ Stage 1 æ‰€æœ‰æµ‹è¯•
- ç¼–å†™æµ‹è¯•æŠ¥å‘Š
- è¯„ä¼° Stage 2 çš„å¯è¡Œæ€§

### ä¸‹å‘¨

- å¼€å§‹ Stage 2 (å¦‚æœ Stage 1 æˆåŠŸ)
- æˆ–è°ƒè¯• Stage 1 çš„é—®é¢˜

---

**æ€»ç»“**: è¿™æ˜¯ä¸€ä¸ªæ›´ç°å®ã€å¯æ‰§è¡Œçš„æµ‹è¯•æ–¹æ¡ˆï¼ŒåŸºäºæˆ‘ä»¬å½“å‰çš„è¿›åº¦ï¼Œé¿å…äº†åŸæ–¹æ¡ˆä¸­çš„ç†æƒ³åŒ–å‡è®¾ã€‚æˆ‘ä»¬å¯ä»¥ç«‹å³å¼€å§‹ Stage 1 çš„æµ‹è¯•ï¼

ä½ æƒ³å…ˆä»å“ªä¸ªæµ‹è¯•å¼€å§‹ï¼Ÿæˆ‘å»ºè®®ä» `test_1_1_compilation.sh` å¼€å§‹ã€‚
