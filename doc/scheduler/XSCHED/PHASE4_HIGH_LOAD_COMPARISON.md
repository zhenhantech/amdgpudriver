# Phase 4 高负载对比分析：Baseline vs XSched

**测试日期**: 2026-01-28  
**测试配置**: Test 4 - 双模型高负载（Intensive）  
**测试时长**: 180 秒 (3 分钟)

---

## 🔧 测试配置

### High Priority Task (高优先级)
- **模型**: ResNet-18
- **请求率**: 20 req/s (50ms interval)
- **设备**: cuda:0
- **期望**: 低延迟，优先保障

### Low Priority Task (低优先级)
- **模型**: ResNet-50
- **Batch Size**: 1024 (大批次)
- **模式**: 连续推理
- **设备**: cuda:0 (与高优先级任务共享)
- **期望**: 充分利用剩余资源

### 系统环境
- **GPU**: AMD Instinct MI308X (8 GPUs)
- **ROCm**: 6.4.0
- **PyTorch**: 2.7.1+rocm6.4.1

---

## 📊 High Priority Task 性能对比

### ResNet-18 (20 req/s) - 高优先级任务

| 指标 | Baseline (Native) | XSched | 改善目标 | 状态 |
|------|-------------------|--------|----------|------|
| **总请求数** | 3596 | ❌ N/A | - | 测试失败 |
| **达成率** | 100% (3596/3600) | ❌ N/A | - | - |
| **实际吞吐** | 19.98 req/s | ❌ N/A | 保持 ~20 | - |
| **平均延迟** | 8.14 ms | ❌ N/A | <5 ms | - |
| **P50 延迟** | 7.55 ms | ❌ N/A | <5 ms | - |
| **P95 延迟** | 15.23 ms | ❌ N/A | <10 ms | - |
| **P99 延迟** | **19.62 ms** ⚠️ | ❌ N/A | **<10 ms** ⭐ | - |
| **最大延迟** | 23.97 ms | ❌ N/A | <15 ms | - |

#### 分析

**Baseline 问题**：
- ✅ 吞吐量达标 (19.98 ≈ 20 req/s)
- ⚠️ **P99 延迟过高** (19.62 ms)
- ⚠️ 延迟波动大 (Max 23.97 ms)
- 📈 相比标准负载 P99 增加 **7.4 倍** (2.65ms → 19.62ms)

**XSched 理论预期**：
- 🎯 高优先级任务应获得优先调度
- 🎯 P99 延迟应接近标准负载 (~3-5 ms)
- 🎯 延迟波动应明显减小
- 🎯 即使在极高负载下也能保持低延迟

**实际测试结果**：
- ❌ XSched 推理失败 (MIOpen Error)
- ❌ 无法获得实际性能数据

---

## 📊 Low Priority Task 性能对比

### ResNet-50 (batch=1024) - 低优先级任务

| 指标 | Baseline (Native) | XSched | 预期 | 状态 |
|------|-------------------|--------|------|------|
| **总迭代数** | 355 | ❌ N/A | ~300-350 | 测试失败 |
| **Batch Size** | 1024 | ❌ N/A | 1024 | - |
| **迭代吞吐** | 1.97 iter/s | ❌ N/A | ~1.5-2.0 | - |
| **图像吞吐** | 2015.7 img/s | ❌ N/A | ~1500-2000 | - |
| **GPU 时间占用** | ~80-85% (估算) | ❌ N/A | ~70-75% | - |

#### 分析

**Baseline 表现**：
- ✅ 充分利用了 GPU 资源
- ✅ 大 batch size 提升了整体吞吐量
- ⚠️ 对高优先级任务造成干扰（导致其 P99 增加）

**XSched 理论预期**：
- 🎯 应主动让出资源给高优先级任务
- 🎯 吞吐量可能略降 (10-20%)，这是合理的权衡
- 🎯 但整体 GPU 利用率应保持健康

**实际测试结果**：
- ❌ XSched 推理失败
- ❌ 无法验证资源调度策略

---

## 🔍 详细对比：延迟分布

### High Priority Task 延迟详情

#### Baseline (Native Scheduler)
```
请求数: 3596
时长: 180.02 秒
目标: 20 req/s

延迟统计 (ms):
  Min:  -        (数据未记录)
  Avg:  8.14     ⚠️ 高于理想值
  P50:  7.55     ⚠️ 
  P90:  -        (未记录)
  P95:  15.23    ⚠️⚠️
  P99:  19.62    ⚠️⚠️⚠️ 严重超标！
  Max:  23.97    ⚠️⚠️⚠️

延迟分布特征:
  - 平均值与 P50 接近 → 大部分请求正常
  - P95-P99 急剧升高 → 尾部延迟严重
  - Max 接近 P99 → 极端情况不多，但存在
```

#### XSched (预期)
```
理论预期延迟 (ms):
  Min:  2.5      (接近硬件下限)
  Avg:  3-4      (略高于单模型)
  P50:  3.0      
  P90:  4.0      
  P95:  5.0      ← 优化目标
  P99:  <10.0    ← 关键指标！
  Max:  <15.0    

延迟分布特征:
  - 整体延迟应明显降低
  - 尾部延迟应得到有效控制
  - P99 应接近标准负载水平
```

#### 实际结果
```
❌ 测试失败
错误: miopenStatusUnknownError
     Failed to launch kernel: invalid device ordinal
```

---

## 📈 对比标准负载与高负载

### High Priority Task (ResNet-18) 在不同负载下的表现

| 负载类型 | 请求率 | 并发模型 | P99 延迟 | 对比基准 |
|---------|--------|----------|----------|----------|
| **单模型** (Test 2) | - | 无 | 2.71 ms | 1.00x (基准) |
| **标准负载** (Test 3) | 10 req/s | ResNet-50 (batch=8) | 2.65 ms | 0.98x ✅ |
| **高负载** (Test 4) | 20 req/s | ResNet-50 (batch=1024) | **19.62 ms** | **7.24x** ⚠️⚠️⚠️ |

#### 关键发现

1. **标准负载几乎无影响**
   - P99: 2.71ms → 2.65ms (略有改善！)
   - 说明：GPU 资源充足，两个任务互不干扰

2. **高负载严重退化** ⭐
   - P99: 2.65ms → 19.62ms (增加 **7.4 倍**)
   - 说明：GPU 资源竞争激烈，Native scheduler 无法有效保护高优先级任务

3. **XSched 的价值**
   - 在标准负载下可能无明显差异（资源充足）
   - 在高负载下应显示出**显著优势**（这正是需要调度器的场景）

---

## 📊 Low Priority Task 吞吐量对比

### ResNet-50 在不同配置下的吞吐量

| 配置 | Batch Size | 迭代吞吐 | 图像吞吐 | 对比 |
|------|-----------|----------|----------|------|
| **标准负载** (Test 3) | 8 | 166.46 iter/s | 1331.7 img/s | 基准 |
| **高负载** (Test 4) | 1024 | 1.97 iter/s | 2015.7 img/s | **+51.3%** ✅ |

#### 分析

**Batch Size 的影响**：
- 小 batch (8): 高迭代率，但总吞吐量受限
- 大 batch (1024): 低迭代率，但充分利用 GPU 并行性
- **大 batch 提升了 51% 的图像处理吞吐量**

**对高优先级任务的影响**：
- 标准负载 (batch=8): High P99 = 2.65 ms ✅ 几乎无影响
- 高负载 (batch=1024): High P99 = 19.62 ms ⚠️ 严重影响

**结论**：
- Batch=1024 虽然提升了低优先级任务的吞吐量
- 但严重损害了高优先级任务的延迟保障
- **这正是需要优先级调度的典型场景**

---

## 🎯 XSched 应实现的改善

### 目标 1: 降低 High Priority P99 延迟

| 场景 | Baseline | XSched 目标 | 改善幅度 |
|------|----------|------------|----------|
| 高负载 | 19.62 ms | **<10 ms** | **-50%+** |

**实现方式**：
- 高优先级任务应抢占 GPU 资源
- 低优先级任务应主动让出计算时间
- 保障高优先级任务的调度延迟

### 目标 2: 保持 Low Priority 合理吞吐

| 指标 | Baseline | XSched 目标 | 权衡 |
|------|----------|------------|------|
| 图像吞吐 | 2015.7 img/s | **~1600-1800 img/s** | 损失 10-20% |

**实现方式**：
- 低优先级任务在空闲时段运行
- 避免完全饿死低优先级任务
- 平衡资源利用率与公平性

### 目标 3: 提升整体系统效率

| 指标 | 描述 | 目标 |
|------|------|------|
| GPU 利用率 | 保持高利用率 | >85% |
| 调度延迟 | 高优先级任务的调度等待 | <1 ms |
| 上下文切换 | 任务切换开销 | 最小化 |

---

## 🔴 当前问题：XSched 运行时错误

### 错误现象
```
✅ XSched 库加载成功
   [INFO @ T65829 @ 12:20:33.297655] using app-managed scheduler

❌ 推理失败
   MIOpen Error: Failed to launch kernel: invalid device ordinal
   RuntimeError: miopenStatusUnknownError
```

### 影响
- ❌ 无法获得 XSched 的实际性能数据
- ❌ 无法验证优先级调度策略
- ❌ 无法进行 Baseline vs XSched 的真实对比

### 可能原因
1. **多 GPU 设备管理问题**
   - MI308X 有 8 个 GPU
   - XSched 可能错误处理了设备索引

2. **MIOpen 兼容性问题**
   - XSched 拦截 HIP API 时影响了 MIOpen
   - Kernel 参数传递可能有误

3. **符号版本问题**
   - 虽然符号导出正确，但运行时行为可能不兼容

### 调试建议
1. **简化测试环境**
   - 使用单个 GPU: `CUDA_VISIBLE_DEVICES=0`
   - 使用简单模型（不依赖 MIOpen）
   - 测试基础 tensor 操作

2. **启用详细日志**
   ```bash
   export XSCHED_LOG_LEVEL=TRACE
   export AMD_SERIALIZE_KERNEL=3
   export MIOPEN_LOG_LEVEL=5
   ```

3. **检查设备管理**
   - 验证 XSched 如何拦截 `hipSetDevice`
   - 检查设备 ordinal 的映射逻辑

---

## 📉 Baseline 性能退化分析

### 为什么 High Priority P99 增加了 7.4 倍？

#### 假设 1: GPU 资源饱和
- **标准负载**: ResNet-50 batch=8 占用约 30-40% GPU
- **高负载**: ResNet-50 batch=1024 占用约 80-85% GPU
- **结果**: 高优先级任务需要等待 GPU 空闲

#### 假设 2: FIFO 调度无优先级
- Native scheduler 使用 FIFO 队列
- 高优先级任务和低优先级任务平等对待
- 当低优先级的大 kernel 正在执行时，高优先级必须等待

#### 假设 3: 内存带宽竞争
- Batch=1024 需要大量内存访问
- 高优先级任务的小请求被阻塞
- HBM 带宽成为瓶颈

#### 假设 4: CU (Compute Unit) 占用
- 大 batch 占用了大部分 CU
- 小 batch 的高优先级任务等待 CU 释放
- 调度粒度过粗

### 验证方法
1. **GPU 利用率分析** (需要工具)
   - `rocm-smi` 监控 GPU 使用率
   - `rocprof` 分析 kernel 执行时间

2. **Timeline 追踪** (需要工具)
   - 使用 ROCm tracer 记录 kernel 执行顺序
   - 分析是否存在长时间阻塞

3. **对比实验**
   - 测试不同的 batch size (256, 512, 1024)
   - 观察 P99 延迟的变化趋势

---

## 🎓 理论分析：XSched 应如何工作

### XSched 论文中的关键机制

#### 1. 优先级队列
- 高优先级任务进入专用队列
- 低优先级任务进入后台队列
- 调度器优先处理高优先级队列

#### 2. 抢占机制
- 当高优先级任务到达时
- 正在运行的低优先级 kernel 应被抢占
- GPU 资源重新分配给高优先级任务

#### 3. 时间片调度
- 低优先级任务获得有限的时间片
- 时间片到期后强制切换
- 防止低优先级任务长时间占用 GPU

### 预期效果

#### 在我们的测试场景中

**High Priority (ResNet-18, 20 req/s)**:
- 到达率: 每 50ms 一个请求
- 理想延迟: ~3ms (基于单模型基准)
- **XSched 应保证**: 即使低优先级占用 GPU，也能在 <10ms 内完成

**Low Priority (ResNet-50, batch=1024)**:
- 单次推理时间: ~500ms (1/1.97)
- **XSched 应做**: 将 500ms 分成多个时间片，在时间片之间插入高优先级任务
- **预期结果**: 高优先级延迟显著降低，低优先级吞吐量略降

---

## 📊 性能对比总结表

### High Priority Task (ResNet-18, 20 req/s)

| 指标 | Baseline | XSched (预期) | XSched (实际) | 改善目标 |
|------|----------|---------------|---------------|----------|
| 吞吐量 (req/s) | 19.98 ✅ | ~19.9 | ❌ 失败 | 保持 |
| P50 延迟 (ms) | 7.55 | ~3.5 | ❌ 失败 | **-53%** |
| P95 延迟 (ms) | 15.23 | ~5.0 | ❌ 失败 | **-67%** |
| **P99 延迟 (ms)** | **19.62** ⚠️ | **<10.0** | ❌ 失败 | **-49%+** ⭐ |
| Max 延迟 (ms) | 23.97 | ~12.0 | ❌ 失败 | **-50%** |

### Low Priority Task (ResNet-50, batch=1024)

| 指标 | Baseline | XSched (预期) | XSched (实际) | 权衡 |
|------|----------|---------------|---------------|------|
| 迭代吞吐 (iter/s) | 1.97 | ~1.6-1.8 | ❌ 失败 | -10% ~ -20% |
| 图像吞吐 (img/s) | 2015.7 | ~1640-1840 | ❌ 失败 | -10% ~ -20% |
| GPU 时间占用 | ~80-85% | ~70-75% | ❌ 失败 | 让出资源 |

### 整体系统

| 指标 | Baseline | XSched (预期) | XSched (实际) |
|------|----------|---------------|---------------|
| 高优先级 QoS | ❌ 差 (P99 19.62ms) | ✅ 优 (P99 <10ms) | ❌ 测试失败 |
| 低优先级公平性 | ✅ 高 | ⚠️ 中 (略降) | ❌ 测试失败 |
| GPU 利用率 | ✅ 高 (~85%) | ✅ 高 (~80%) | ❌ 测试失败 |
| 系统灵活性 | ❌ 无优先级控制 | ✅ 可配置优先级 | ❌ 测试失败 |

---

## 🎯 结论

### ✅ 通过 Baseline 测试证明了问题存在

1. **Native Scheduler 的瓶颈明确**
   - 高负载下 P99 延迟增加 **7.4 倍** (2.65ms → 19.62ms)
   - 无法有效保障高优先级任务的 SLA
   - 证明了优先级调度的必要性

2. **测试设计有效**
   - 标准负载 vs 高负载形成鲜明对比
   - 数据一致性验证通过（误差 <1%）
   - 多线程真正并发执行

3. **建立了完整的性能基准**
   - 单模型基准: P99 = 2.71 ms
   - 标准负载: P99 = 2.65 ms
   - 高负载: P99 = 19.62 ms

### ❌ XSched 实现遇到技术问题

1. **无法获得实际性能数据**
   - XSched 加载成功但推理失败
   - MIOpen kernel 错误阻止了测试

2. **需要进一步调试**
   - 多 GPU 环境问题
   - MIOpen 兼容性
   - 设备管理逻辑

### 🎯 下一步建议

#### 短期（调试 XSched）
1. **简化测试**
   - 单 GPU 环境
   - 不使用 MIOpen 的简单模型
   - 基础 tensor 操作

2. **详细诊断**
   - 启用 TRACE 级别日志
   - 使用 ROCm profiler
   - 联系 XSched 开发者

#### 中期（替代方案）
1. **探索 AMD 原生方案**
   - ROCm 是否提供优先级 API？
   - HSA queue priority

2. **研究其他调度器**
   - NVIDIA MPS/MIG 的 AMD 等价物
   - 自定义调度器实现

#### 长期（论文验证）
1. **完整性能对比**
   - 修复 XSched 后重新测试
   - 验证理论预期

2. **扩展测试场景**
   - 更多模型组合
   - 不同优先级配置
   - 多租户场景

---

## 📁 相关文件

### 测试报告
- `PHASE4_COMPLETE_TEST_REPORT.md` - 完整测试报告
- `PHASE4_QUICK_SUMMARY.md` - 快速总结
- `PHASE4_HIGH_LOAD_COMPARISON.md` - 本文档

### 测试日志
- `phase4_log/test4_intensive_20260128_*.log` - 高负载测试日志

### 数据文件 (Docker 内)
- `/data/dockercode/test_results_phase4/baseline_intensive_result.json`
- `/data/dockercode/test_results_phase4/xsched_intensive_result.json` (失败记录)

---

**报告版本**: 1.0  
**生成时间**: 2026-01-28  
**状态**: Baseline 数据完整，XSched 需要调试
