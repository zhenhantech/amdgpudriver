# XSched Phase 2: å®æ–½è¿›å±•ä¸é—®é¢˜åˆ†æ

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

- **åˆ›å»ºæ—¶é—´**: 2026-01-27
- **æµ‹è¯•å¹³å°**: AMD MI308X (Docker: zhenaiter)
- **çŠ¶æ€**: é‡åˆ° HIP Context å†²çªé—®é¢˜

---

## âœ… å·²å®Œæˆçš„å·¥ä½œ

### 1. XSched C API Python ç»‘å®š

æˆåŠŸä½¿ç”¨ `ctypes` åˆ›å»ºäº†å®Œæ•´çš„ XSched C API ç»‘å®šï¼š

```python
# åŠ è½½ XSched åº“
libpreempt = ctypes.CDLL("/workspace/xsched/output/lib/libpreempt.so")
libhalhip = ctypes.CDLL("/workspace/xsched/output/lib/libhalhip.so")

# å®šä¹‰ç±»å‹
XQueueHandle = ctypes.c_uint64
HwQueueHandle = ctypes.c_uint64
Priority = ctypes.c_int32

# å®šä¹‰å‡½æ•°ç­¾å
libpreempt.XHintSetScheduler.argtypes = [XSchedulerType, XPolicyType]
libpreempt.XHintPriority.argtypes = [XQueueHandle, Priority]
libpreempt.XQueueCreate.argtypes = [...]
libhalhip.HipQueueCreate.argtypes = [...]
```

**çŠ¶æ€**: âœ… å®Œæˆ

### 2. XSchedQueue åŒ…è£…ç±»

åˆ›å»ºäº† Python ç±»æ¥ç®¡ç† XSched é˜Ÿåˆ—ï¼š

```python
class XSchedQueue:
    def __init__(self, stream: torch.cuda.Stream, priority: int):
        # 1. è·å– HIP Stream å¥æŸ„
        hip_stream = ctypes.c_void_p(stream.cuda_stream)
        
        # 2. åˆ›å»º HwQueue
        libhalhip.HipQueueCreate(ctypes.byref(self.hwq), hip_stream)
        
        # 3. åˆ›å»º XQueue
        libpreempt.XQueueCreate(ctypes.byref(self.xq), self.hwq, ...)
        
        # 4. è®¾ç½®ä¼˜å…ˆçº§
        libpreempt.XHintPriority(self.xq, priority)
```

**çŠ¶æ€**: âœ… å®Œæˆ

### 3. å®Œæ•´çš„æµ‹è¯•è„šæœ¬

åˆ›å»ºäº†ä¸¤ä¸ªæµ‹è¯•è„šæœ¬ï¼š

1. **`test_xsched_integration.py`**: å®Œæ•´çš„ BERT æ¨ç†æµ‹è¯•ï¼ŒåŒ…å« Baseline å’Œ XSched å¯¹æ¯”
2. **`test_xsched_simple.py`**: ç®€å•çš„ XSched é›†æˆéªŒè¯æµ‹è¯•

**çŠ¶æ€**: âœ… å®Œæˆ

### 4. æŠ€æœ¯æ–‡æ¡£

åˆ›å»ºäº†è¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£ï¼š

- **`XSched_Phase2_çœŸå®GPUä¼˜å…ˆçº§è°ƒåº¦å®ç°æŠ¥å‘Š.md`**: å®Œæ•´çš„æŠ€æœ¯è¯´æ˜å’Œä½¿ç”¨æŒ‡å—
- **`XSched_Phase2_å®æ–½è¿›å±•ä¸é—®é¢˜åˆ†æ.md`**: æœ¬æ–‡æ¡£

**çŠ¶æ€**: âœ… å®Œæˆ

---

## âŒ é‡åˆ°çš„é—®é¢˜

### é—®é¢˜æè¿°

åœ¨è¿è¡Œæµ‹è¯•æ—¶ï¼Œé‡åˆ°ä»¥ä¸‹é”™è¯¯ï¼š

```
[INFO @ T19594 @ 05:15:13.467276] using local scheduler with policy HPF
[ERRO @ T19594 @ 05:15:13.481502] hip error 709: context is destroyed @ /workspace/xsched/platforms/hip/hal/src/hip_queue.cpp:32
```

**é”™è¯¯ä»£ç **: `hip error 709` - `hipErrorContextIsDestroyed`

### é—®é¢˜åˆ†æ

#### 1. HIP Context å†²çª

PyTorch å’Œ XSched éƒ½éœ€è¦ç®¡ç† HIP contextï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PyTorch (torch.cuda)                                        â”‚
â”‚  - åˆ›å»ºå¹¶ç®¡ç†è‡ªå·±çš„ HIP context                             â”‚
â”‚  - åˆ›å»º HIP Streams                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ XSched (libhalhip.so)                                       â”‚
â”‚  - å°è¯•è®¿é—® PyTorch åˆ›å»ºçš„ HIP Stream                       â”‚
â”‚  - å¯èƒ½åœ¨ context è¢«é”€æ¯åè®¿é—®                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å¯èƒ½çš„åŸå› **ï¼š
1. **Context ç”Ÿå‘½å‘¨æœŸç®¡ç†**: PyTorch çš„ HIP context å¯èƒ½åœ¨ XSched è®¿é—®ä¹‹å‰æˆ–æœŸé—´è¢«é”€æ¯
2. **å¤šçº¿ç¨‹é—®é¢˜**: HIP context æ˜¯çº¿ç¨‹å±€éƒ¨çš„ï¼ŒXSched å¯èƒ½åœ¨ä¸åŒçš„çº¿ç¨‹ä¸­è®¿é—®
3. **åˆå§‹åŒ–é¡ºåº**: XSched åˆå§‹åŒ–æ—¶ï¼ŒPyTorch çš„ HIP context å¯èƒ½è¿˜æœªå®Œå…¨å»ºç«‹

#### 2. é”™è¯¯å‘ç”Ÿä½ç½®

é”™è¯¯å‘ç”Ÿåœ¨ `/workspace/xsched/platforms/hip/hal/src/hip_queue.cpp:32`ï¼š

```cpp
// hip_queue.cpp (æ¨æµ‹)
XResult HipQueueCreate(HwQueueHandle *hwq, hipStream_t stream) {
    // Line 32: å°è¯•è®¿é—® HIP context
    hipError_t err = hipStreamQuery(stream);  // æˆ–ç±»ä¼¼çš„ HIP API è°ƒç”¨
    if (err == hipErrorContextIsDestroyed) {
        // é”™è¯¯ï¼šcontext å·²è¢«é”€æ¯
        return kXSchedErrorHardware;
    }
    ...
}
```

---

## ğŸ” å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ä½¿ç”¨ LD_PRELOAD é€æ˜æ‹¦æˆªï¼ˆæ¨èï¼‰â­â­â­â­â­

XSched çš„è®¾è®¡åˆè¡·å°±æ˜¯é€šè¿‡ `LD_PRELOAD` é€æ˜åœ°æ‹¦æˆª HIP API è°ƒç”¨ï¼Œè€Œä¸æ˜¯ç›´æ¥åœ¨ Python ä¸­è°ƒç”¨ C APIã€‚

#### å®ç°æ­¥éª¤

1. **ä½¿ç”¨ XSched çš„ Shim åº“**:

```bash
export LD_PRELOAD=/workspace/xsched/output/lib/libshimhip.so
```

2. **è¿è¡Œæ™®é€šçš„ PyTorch ä»£ç **:

```python
# ä¸éœ€è¦ä»»ä½• XSched C API è°ƒç”¨ï¼
import torch

# è®¾ç½®ç¯å¢ƒå˜é‡æ¥é…ç½® XSched
os.environ['XSCHED_SCHEDULER'] = 'local'
os.environ['XSCHED_POLICY'] = 'HPF'  # Highest Priority First

# æ­£å¸¸ä½¿ç”¨ PyTorch
stream1 = torch.cuda.Stream(priority=-1)  # é«˜ä¼˜å…ˆçº§
stream2 = torch.cuda.Stream(priority=0)   # ä½ä¼˜å…ˆçº§

with torch.cuda.stream(stream1):
    output1 = model(input1)  # XSched ä¼šè‡ªåŠ¨æ‹¦æˆªå¹¶ç®¡ç†

with torch.cuda.stream(stream2):
    output2 = model(input2)
```

3. **XSched è‡ªåŠ¨æ‹¦æˆª**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Python ä»£ç                                                   â”‚
â”‚  stream = torch.cuda.Stream(priority=-1)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ libshimhip.so (LD_PRELOAD)                                  â”‚
â”‚  - æ‹¦æˆª hipStreamCreate() è°ƒç”¨                              â”‚
â”‚  - è‡ªåŠ¨åˆ›å»º XQueue å¹¶è®¾ç½®ä¼˜å…ˆçº§                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ XSched è°ƒåº¦å™¨                                               â”‚
â”‚  - ç®¡ç†æ‰€æœ‰ XQueue                                          â”‚
â”‚  - æ ¹æ®ä¼˜å…ˆçº§è°ƒåº¦                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¼˜ç‚¹**ï¼š
- âœ… å®Œå…¨é€æ˜ï¼Œä¸éœ€è¦ä¿®æ”¹ Python ä»£ç 
- âœ… é¿å… context ç®¡ç†å†²çª
- âœ… è¿™æ˜¯ XSched è®¾è®¡çš„æ­£ç¡®ä½¿ç”¨æ–¹å¼

**ç¼ºç‚¹**ï¼š
- âš ï¸ éœ€è¦è®¾ç½® `LD_PRELOAD`
- âš ï¸ è°ƒè¯•å¯èƒ½æ›´å›°éš¾

### æ–¹æ¡ˆ 2: ä¿®å¤ Context ç®¡ç†

ç›´æ¥ä¿®å¤ Python ä»£ç ä¸­çš„ context ç®¡ç†é—®é¢˜ã€‚

#### å¯èƒ½çš„ä¿®å¤æ–¹æ³•

1. **ç¡®ä¿ Context æŒä¹…åŒ–**:

```python
# åœ¨å…¨å±€ä½œç”¨åŸŸåˆ›å»ºä¸€ä¸ªæŒä¹…çš„ CUDA tensor
_cuda_context_holder = torch.zeros(1, device='cuda:0')

def create_xsched_queue(stream, priority):
    # ç¡®ä¿ context å­˜åœ¨
    torch.cuda.synchronize()
    _cuda_context_holder.cpu()  # å¼ºåˆ¶è®¿é—® context
    
    # åˆ›å»º XQueue
    ...
```

2. **ä½¿ç”¨ CUDA Primary Context**:

```python
import ctypes
libcuda = ctypes.CDLL('libamdhip64.so')

# è·å–å¹¶ä¿æŒ primary context
device = 0
ctx = ctypes.c_void_p()
libcuda.hipDevicePrimaryCtxRetain(ctypes.byref(ctx), device)

# åˆ›å»º XQueue
...

# åœ¨ç¨‹åºç»“æŸæ—¶é‡Šæ”¾
libcuda.hipDevicePrimaryCtxRelease(device)
```

3. **å»¶è¿Ÿ XQueue åˆ›å»º**:

```python
# åœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶æ‰åˆ›å»º XQueueï¼Œè€Œä¸æ˜¯åœ¨åˆå§‹åŒ–æ—¶
class LazyXSchedQueue:
    def __init__(self, stream, priority):
        self.stream = stream
        self.priority = priority
        self._xq = None
    
    def ensure_created(self):
        if self._xq is None:
            # åœ¨è¿™é‡Œåˆ›å»º XQueue
            ...
```

**ä¼˜ç‚¹**ï¼š
- âœ… ä¿æŒç›´æ¥è°ƒç”¨ C API çš„æ–¹å¼
- âœ… æ›´ç²¾ç»†çš„æ§åˆ¶

**ç¼ºç‚¹**ï¼š
- âŒ éœ€è¦æ·±å…¥ç†è§£ HIP context ç®¡ç†
- âŒ å¯èƒ½ä»ç„¶æœ‰å…¶ä»–éšè—çš„å†²çª

### æ–¹æ¡ˆ 3: ä½¿ç”¨ XSched çš„ C++ ç¤ºä¾‹ä½œä¸ºå‚è€ƒ

ç›´æ¥ä½¿ç”¨ C++ ç¼–å†™æµ‹è¯•ç¨‹åºï¼Œé¿å… Python/PyTorch çš„ context ç®¡ç†é—®é¢˜ã€‚

```cpp
// test_xsched_bert.cpp
#include <hip/hip_runtime.h>
#include "xsched/xsched.h"
#include "xsched/hip/hal.h"

int main() {
    // åˆå§‹åŒ– HIP
    hipSetDevice(0);
    
    // åˆ›å»º Stream
    hipStream_t stream;
    hipStreamCreate(&stream);
    
    // åˆ›å»º XQueue
    HwQueueHandle hwq;
    HipQueueCreate(&hwq, stream);
    
    XQueueHandle xq;
    XQueueCreate(&xq, hwq, kPreemptLevelBlock, kQueueCreateFlagNone);
    
    // è®¾ç½®ä¼˜å…ˆçº§
    XHintPriority(xq, 3);
    
    // è¿è¡Œ kernel
    ...
    
    return 0;
}
```

**ä¼˜ç‚¹**ï¼š
- âœ… é¿å… Python/PyTorch çš„å¤æ‚æ€§
- âœ… æ›´æ¥è¿‘ XSched çš„åŸç”Ÿä½¿ç”¨æ–¹å¼

**ç¼ºç‚¹**ï¼š
- âŒ æ— æ³•ç›´æ¥ä½¿ç”¨ PyTorch çš„æ¨¡å‹
- âŒ éœ€è¦é‡æ–°å®ç° BERT æ¨ç†é€»è¾‘

---

## ğŸ“Š Example 3 çš„æˆåŠŸç»éªŒ

æˆ‘ä»¬ä¹‹å‰æˆåŠŸè¿è¡Œäº† Example 3 (`app_concurrent.hip`)ï¼Œå®ƒä¹Ÿæ˜¯ä½¿ç”¨ XSched C APIã€‚è®©æˆ‘ä»¬åˆ†æå®ƒä¸ºä»€ä¹ˆèƒ½æˆåŠŸï¼š

### Example 3 çš„å…³é”®ç‚¹

1. **çº¯ HIP ä»£ç **:
   - ä¸ä¾èµ– PyTorch
   - ç›´æ¥ä½¿ç”¨ HIP Runtime API

2. **Context ç®¡ç†**:
   ```cpp
   // åœ¨ main å‡½æ•°å¼€å§‹æ—¶
   hipSetDevice(0);  // æ˜¾å¼è®¾ç½®è®¾å¤‡
   
   // åœ¨ run å‡½æ•°ä¸­
   hipStreamCreate(&stream);  // åˆ›å»º stream
   HipQueueCreate(&hwq, stream);  // ç«‹å³åˆ›å»º HwQueue
   XQueueCreate(&xq, hwq, ...);  // ç«‹å³åˆ›å»º XQueue
   ```

3. **ç”Ÿå‘½å‘¨æœŸç®¡ç†**:
   - Stream, HwQueue, XQueue éƒ½åœ¨åŒä¸€ä¸ªä½œç”¨åŸŸå†…
   - æ²¡æœ‰è·¨çº¿ç¨‹è®¿é—®

### ä¸æˆ‘ä»¬çš„ä»£ç çš„å·®å¼‚

| ç»´åº¦ | Example 3 (æˆåŠŸ) | æˆ‘ä»¬çš„ä»£ç  (å¤±è´¥) |
|------|-----------------|------------------|
| **è¯­è¨€** | C++ | Python |
| **HIP ç®¡ç†** | ç›´æ¥ä½¿ç”¨ HIP API | é€šè¿‡ PyTorch é—´æ¥ä½¿ç”¨ |
| **Context** | æ˜¾å¼ç®¡ç† | PyTorch è‡ªåŠ¨ç®¡ç† |
| **ç”Ÿå‘½å‘¨æœŸ** | ç®€å•æ˜ç¡® | å¤æ‚ï¼ˆPython GC + PyTorchï¼‰ |

---

## ğŸ¯ æ¨èçš„ä¸‹ä¸€æ­¥

### çŸ­æœŸæ–¹æ¡ˆï¼ˆç«‹å³å¯è¡Œï¼‰

**ä½¿ç”¨æ–¹æ¡ˆ 1: LD_PRELOAD é€æ˜æ‹¦æˆª**

1. åˆ›å»ºä¸€ä¸ªæ–°çš„æµ‹è¯•è„šæœ¬ `test_xsched_preload.py`
2. ä½¿ç”¨ `LD_PRELOAD` åŠ è½½ `libshimhip.so`
3. è¿è¡Œæ™®é€šçš„ PyTorch ä»£ç ï¼Œè®© XSched è‡ªåŠ¨æ‹¦æˆª

```bash
# è¿è¡Œè„šæœ¬
LD_PRELOAD=/workspace/xsched/output/lib/libshimhip.so \
    python3 test_bert_inference.py
```

### ä¸­æœŸæ–¹æ¡ˆï¼ˆéœ€è¦è°ƒè¯•ï¼‰

**ä¿®å¤ Context ç®¡ç†é—®é¢˜**

1. æ·±å…¥ç ”ç©¶ XSched çš„ HIP HAL å®ç°
2. ç†è§£ PyTorch çš„ HIP context ç®¡ç†æœºåˆ¶
3. æ‰¾åˆ°ä¸¤è€…å…¼å®¹çš„æ–¹å¼

### é•¿æœŸæ–¹æ¡ˆï¼ˆæœ€å½»åº•ï¼‰

**è´¡çŒ®ç»™ XSched é¡¹ç›®**

1. å‘ XSched é¡¹ç›®æŠ¥å‘Šè¿™ä¸ªé—®é¢˜
2. æä¾› PyTorch é›†æˆçš„è¡¥ä¸
3. æ·»åŠ  PyTorch ç¤ºä¾‹åˆ° XSched ä»“åº“

---

## ğŸ“ ç›¸å…³æ–‡ä»¶

1. **æµ‹è¯•è„šæœ¬**:
   - `/mnt/md0/zhehan/code/flashinfer/dockercode/xsched/test_xsched_integration.py`
   - `/mnt/md0/zhehan/code/flashinfer/dockercode/xsched/test_xsched_simple.py`

2. **æ–‡æ¡£**:
   - `/mnt/md0/zhehan/code/coderampup/private_github/amdgpudriver/doc/scheduler/XSCHED/XSched_Phase2_çœŸå®GPUä¼˜å…ˆçº§è°ƒåº¦å®ç°æŠ¥å‘Š.md`
   - `/mnt/md0/zhehan/code/coderampup/private_github/amdgpudriver/doc/scheduler/XSCHED/XSched_Phase2_å®æ–½è¿›å±•ä¸é—®é¢˜åˆ†æ.md`

3. **å‚è€ƒä»£ç **:
   - `/workspace/xsched/examples/Linux/3_intra_process_sched/app_concurrent.hip` (æˆåŠŸçš„ä¾‹å­)
   - `/workspace/xsched/platforms/hip/hal/src/hip_queue.cpp` (é”™è¯¯å‘ç”Ÿä½ç½®)

---

## ğŸ’¡ æ€»ç»“

### å·²å®Œæˆ
- âœ… XSched C API Python ç»‘å®š
- âœ… XSchedQueue åŒ…è£…ç±»
- âœ… å®Œæ•´çš„æµ‹è¯•è„šæœ¬
- âœ… è¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£

### å½“å‰é—®é¢˜
- âŒ HIP Context å†²çª (`hipErrorContextIsDestroyed`)
- âŒ PyTorch å’Œ XSched çš„ context ç®¡ç†ä¸å…¼å®¹

### æ¨èæ–¹æ¡ˆ
- ğŸ¯ **é¦–é€‰**: ä½¿ç”¨ `LD_PRELOAD` æ–¹å¼ï¼ˆæ–¹æ¡ˆ 1ï¼‰
- ğŸ¯ **å¤‡é€‰**: ä¿®å¤ context ç®¡ç†ï¼ˆæ–¹æ¡ˆ 2ï¼‰
- ğŸ¯ **æœ€å**: ä½¿ç”¨çº¯ C++ å®ç°ï¼ˆæ–¹æ¡ˆ 3ï¼‰

### å…³é”®æ´å¯Ÿ
**XSched çš„è®¾è®¡åˆè¡·æ˜¯é€šè¿‡ `LD_PRELOAD` é€æ˜æ‹¦æˆªï¼Œè€Œä¸æ˜¯ç›´æ¥åœ¨åº”ç”¨ä»£ç ä¸­è°ƒç”¨ C APIã€‚** æˆ‘ä»¬åº”è¯¥éµå¾ªè¿™ä¸ªè®¾è®¡ç†å¿µï¼Œä½¿ç”¨ Shim åº“çš„æ–¹å¼æ¥é›†æˆ XSchedã€‚

---

## ğŸ”— å‚è€ƒèµ„æ–™

1. **XSched è®ºæ–‡**: `/mnt/md0/zhehan/code/coderampup/private_github/amdgpudriver/doc/scheduler/papers/XSched_Preemptive Scheduling for Diverse XPUs.pdf`
2. **XSched README**: `/workspace/xsched/README.md`
3. **HIP Error Codes**: https://rocm.docs.amd.com/projects/HIP/en/latest/reference/kernel_language.html#error-codes
4. **PyTorch CUDA Streams**: https://pytorch.org/docs/stable/notes/cuda.html#cuda-streams

---

**åˆ›å»ºæ—¶é—´**: 2026-01-27  
**æœ€åæ›´æ–°**: 2026-01-27  
**çŠ¶æ€**: é—®é¢˜åˆ†æå®Œæˆï¼Œç­‰å¾…å®æ–½è§£å†³æ–¹æ¡ˆ

